{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Summary:   \n",
    "- Load and clean data based on conclusions from EDA process\n",
    "- Generating features for monthly retention prediction \n",
    "- Event frequency features for last_1_day, last_3_day, last_7_day, last_14_day, last_30_day\n",
    "- Recency feature: gaps between last usage and 05/01/2017\n",
    "- Device feature: device the user hold\n",
    "- Total play time feature: total music playing time for users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "# We use matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This statement allow to display plot without asking to\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Feature_Engineer\") \\\n",
    "    .config(\"Spark.some.config.option\", \"Value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, event: string, device: string, song_id: string, song_type: string, date: string, play_time: string, song_length: string, paid_flag: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('../data/event_ds.csv',header=True).cache()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+-------+---------+----------+---------+-----------+---------+\n",
      "|      uid|event|device|song_id|song_type|      date|play_time|song_length|paid_flag|\n",
      "+---------+-----+------+-------+---------+----------+---------+-----------+---------+\n",
      "|167923158|    P|    ar| 985228|        0|2017-04-01|      251|        251|        0|\n",
      "|168045107|    P|    ar|6818758|        0|2017-04-01|        0|       1683|        0|\n",
      "|167580792|    P|    ar|6989313|        0|2017-04-01|      113|        113|        0|\n",
      "|167575198|    P|    ar|9953526|        0|2017-04-01|      277|        277|        0|\n",
      "|168045107|    P|    ar|6796145|        0|2017-04-01|        0|       1799|        0|\n",
      "+---------+-----+------+-------+---------+----------+---------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, event: string, device: string, song_id: string, song_type: string, date: date, play_time: int, song_length: int, paid_flag: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn('date',F.col('date').cast('date'))\n",
    "df = df.withColumn('play_time',F.col('play_time').cast('int'))\n",
    "df = df.withColumn('song_length',F.col('song_length').cast('int'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((F.col('song_length') > 0) | (F.col('event') != 'P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+-------+---------+----------+---------+-----------+---------+\n",
      "|      uid|event|device|song_id|song_type|      date|play_time|song_length|paid_flag|\n",
      "+---------+-----+------+-------+---------+----------+---------+-----------+---------+\n",
      "|167923158|    P|    ar| 985228|        0|2017-04-01|      251|        251|        0|\n",
      "|168045107|    P|    ar|6818758|        0|2017-04-01|        0|       1683|        0|\n",
      "|167580792|    P|    ar|6989313|        0|2017-04-01|      113|        113|        0|\n",
      "|167575198|    P|    ar|9953526|        0|2017-04-01|      277|        277|        0|\n",
      "|168045107|    P|    ar|6796145|        0|2017-04-01|        0|       1799|        0|\n",
      "+---------+-----+------+-------+---------+----------+---------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total_play_time = df.filter(F.col('event') == 'P').groupBy('uid', 'date').agg(\n",
    "    F.sum(F.col('play_time')).alias('total_play_time')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_id = set(df_total_play_time.filter((F.col('total_play_time') > 24 * 60 * 60)).select('uid').toPandas()['uid'])\n",
    "df_filtered = df.filter(~F.col('uid').isin(abnormal_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Label definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label window: 2017-05-01 ~ 2017-05-12 days: 12\n",
      "feature window: 2017-04-01 ~ 2017-04-30 days: 30\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "label_window_size = 12\n",
    "label_window_end_date = parser.parse('2017-05-12').date()\n",
    "label_window_start_date = label_window_end_date - datetime.timedelta(label_window_size - 1)\n",
    "print('label window:',label_window_start_date,'~',label_window_end_date,'days:',label_window_size)\n",
    "\n",
    "feature_window_size = 30\n",
    "feature_window_end_date = label_window_start_date - datetime.timedelta(1)\n",
    "feature_window_start_date = feature_window_end_date  - datetime.timedelta(feature_window_size - 1)\n",
    "print('feature window:',feature_window_start_date,'~',feature_window_end_date,'days:',feature_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the uid I will model\n",
    "df_model_uid = df_filtered.filter((F.col('date')>=feature_window_start_date) & (F.col('date')<=feature_window_end_date))\\\n",
    "                    .select('uid').distinct()\n",
    "# active in label window (active label=0)\n",
    "df_active_uid_in_label_window = df_filtered.filter((F.col('date')>=label_window_start_date) & (F.col('date')<=label_window_end_date))\\\n",
    "                            .select('uid').distinct().withColumn('label',F.lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      uid|label|\n",
      "+---------+-----+\n",
      "|167833570|    0|\n",
      "|167935507|    0|\n",
      "|167635050|    0|\n",
      "|167677985|    0|\n",
      "|167672887|    0|\n",
      "|167883821|    0|\n",
      "|167774834|    0|\n",
      "|167794834|    0|\n",
      "|167772496|    0|\n",
      "|167718296|    0|\n",
      "|167867356|    0|\n",
      "|168034652|    0|\n",
      "|167841001|    0|\n",
      "|153361173|    0|\n",
      "|167882566|    0|\n",
      "|167792246|    0|\n",
      "|167983710|    0|\n",
      "|167979065|    0|\n",
      "|167696079|    0|\n",
      "|167851766|    0|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_active_uid_in_label_window.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare label data (churn label=1; active label=0)\n",
    "df_label = df_model_uid.join(df_active_uid_in_label_window,on=['uid'],how='left')\n",
    "df_label = df_label.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|68074|\n",
      "|    0|62366|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_label.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_data in feature_window\n",
    "df_feature_window = df_filtered.filter((F.col('date')>=feature_window_start_date) & (F.col('date')<=feature_window_end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate frequency features for a list of time windows\n",
    "# using when().otherwise(), and list comprehension trick!\n",
    "def frequency_feature_generation_time_windows(df,event,time_window_list,snapshot_date):\n",
    "    \"\"\"\n",
    "    generate frequency features for one event type and a list of time windows\n",
    "    \"\"\"\n",
    "    df_feature = df \\\n",
    "        .filter(F.col('event')==event) \\\n",
    "        .groupBy('uid') \\\n",
    "        .agg(*[F.sum(F.when((F.col('date')>=snapshot_date-datetime.timedelta(time_window-1)) & (F.col('date')<=snapshot_date),1).otherwise(0)).alias('freq_'+event+'_last_'+str(time_window)) \\\n",
    "                for time_window in time_window_list]\n",
    "            )# *[] opens list and make them comma separated\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+-------------+--------------+--------------+\n",
      "|      uid|freq_S_last_1|freq_S_last_3|freq_S_last_7|freq_S_last_14|freq_S_last_30|\n",
      "+---------+-------------+-------------+-------------+--------------+--------------+\n",
      "|167718831|            0|           43|           47|            64|           136|\n",
      "|167871297|            1|            3|            3|             3|            31|\n",
      "|167979065|            0|            0|            0|             0|            14|\n",
      "|167819127|            0|            0|            0|             0|            16|\n",
      "|167823358|            1|            1|            1|             1|            30|\n",
      "+---------+-------------+-------------+-------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate one event type, all time windows \n",
    "event = 'S'\n",
    "time_window_list = [1,3,7,14,30]\n",
    "snapshot_date = feature_window_end_date\n",
    "df_feature = frequency_feature_generation_time_windows(df_feature_window,event,time_window_list,snapshot_date)\n",
    "df_feature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate frequency features for all event_list, time_window_list\n",
    "event_list = ['P','D','S']\n",
    "time_window_list = [1,3,7,14,30]\n",
    "df_feature_list = []\n",
    "for event in event_list:\n",
    "    df_feature_list.append(frequency_feature_generation_time_windows(df_feature_window,event,time_window_list,snapshot_date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Recency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|      uid|recency|\n",
      "+---------+-------+\n",
      "|167979065|     13|\n",
      "|167946935|      1|\n",
      "|168071350|      1|\n",
      "|167596545|     27|\n",
      "|167586424|     29|\n",
      "|167570658|      8|\n",
      "|167819127|     22|\n",
      "|167794834|      1|\n",
      "|167696079|      1|\n",
      "|167887737|      2|\n",
      "|167981938|      2|\n",
      "|167929480|     30|\n",
      "|167641186|     27|\n",
      "|167976118|      1|\n",
      "|167587629|     28|\n",
      "|167992594|      1|\n",
      "|167587246|      1|\n",
      "|167925319|     17|\n",
      "|167762174|      3|\n",
      "|168015877|      4|\n",
      "+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defined as days from last event\n",
    "# can generate one feature for each type of event\n",
    "df_feature_window.groupBy('uid').agg(\n",
    "   F.datediff(F.lit(label_window_start_date), F.max(F.col('date'))).alias('recency')\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recency = df_feature_window.groupBy('uid').agg(\n",
    "   F.datediff(F.lit(label_window_start_date), F.max(F.col('date'))).alias('recency')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Profile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_device = df_feature_window.select('uid', 'device').distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Total play time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_time = df_feature_window.filter(F.col('event') == 'P').groupBy('uid').agg(\n",
    "    F.sum(F.col('play_time')).alias('total_play_time')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Fancier frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|      uid|80% play counts|\n",
      "+---------+---------------+\n",
      "|167979065|             34|\n",
      "|167946935|            516|\n",
      "|168071350|            276|\n",
      "|167596545|             18|\n",
      "|167586424|             22|\n",
      "|167570658|            269|\n",
      "|167819127|             67|\n",
      "|167794834|            808|\n",
      "|167696079|            217|\n",
      "|167887737|            356|\n",
      "|167981938|             44|\n",
      "|167929480|              8|\n",
      "|167641186|             75|\n",
      "|167976118|            130|\n",
      "|167587629|             12|\n",
      "|167992594|             29|\n",
      "|167587246|            424|\n",
      "|167925319|            144|\n",
      "|167762174|            151|\n",
      "|168015877|            104|\n",
      "+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate counts of songs play 80% of their song length (using play_ds data) for different time window\n",
    "df_feature_window.filter(F.col('event') == 'P').groupBy('uid').agg(\n",
    "    F.sum(F.when((F.col('play_time') >= 0.8 * F.col('song_length')),1).otherwise(0)).alias('80% play counts')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over80play_counts = df_feature_window.filter(F.col('event') == 'P').groupBy('uid').agg(\n",
    "    F.sum(F.when((F.col('play_time') >= 0.8 * F.col('song_length')),1).otherwise(0)).alias('80% play counts')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Form training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_data(df_master,df_feature_list):\n",
    "    for df_feature in df_feature_list:\n",
    "        df_master = df_master.join(df_feature,on='uid',how='left')\n",
    "        df_master.persist() # uncomment if number of joins is too many\n",
    "    return df_master\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all features\n",
    "df_model_final = join_feature_data(df_label,df_feature_list)\n",
    "df_model_final = join_feature_data(df_model_final,[df_recency])\n",
    "df_model_final = join_feature_data(df_model_final,[df_device])\n",
    "df_model_final = join_feature_data(df_model_final,[df_play_time])\n",
    "df_model_final = join_feature_data(df_model_final,[df_over80play_counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final.fillna(0).toPandas().to_csv('../data/df_model_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(conda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
